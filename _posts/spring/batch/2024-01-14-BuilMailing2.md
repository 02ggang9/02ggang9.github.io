---
published: false
title:  "Spring Batch - BDD 내부 메일링 서비스 개발 (2) - ItemReader 성능 튜닝"
categories:
  - spring
---

## 서론

[BDD 내부 메일링 서비스 개발 (1)](https://02ggang9.github.io/spring/BulkMailing1/)에서 전체적인 UI와 마크다운 문법을 지원함으로써 손쉽게 메일을 보낼 수 있었습니다. 하지만 회원 1명에게 보낼 때 마다 걸리는 시간이 4s 걸렸습니다. 100명 기준으로 400s(약 7분), 1만명 기준으로 40000s(약 12시간)이 걸리게 됩니다. 

사태의 심각성을 느끼고 성능 튜닝을 하기위해서 여러 자료를 찾았습니다. 이번 글에서는 Batch에서 item을 읽어오는 방법과 메일링 서비스가 느린 이유, 개선 방법에 대해서 알아보겠습니다.

아래의 내용은 [[Data] Batch Performance 극한으로 끌어올리기: 1억 건 데이터 처리를 위한 노력 / if(kakao)dev2022](https://www.youtube.com/watch?v=2IIwQDIi3ys)을 참고했습니다.


## Chunk Processing

배치 처리가 필요한 이유는 대규모의 데이터를 일괄적으로 처리할 수 없기 때문입니다. 데이터가 1000개일 경우에는 충분히 한번에 처리할 수 있지만 1000만개의 데이터일 경우에는 불가능합니다. 따라서 데이터를 1000개 단위로 나누고, 1만번 처리해야 합니다.

데이터를 나누는 대표적인 방법으로 Pagination이 있습니다. 



데이터를 나누는 방법은 대표적으로 Pagination이 있음. 일반적으로 많이 사용하는 PageItemReader는 RepositoryItemReader, JpaPagingItemReader가 있음.
page number와 page size로 데이터를 잘라옴. MYSQL에서는 이를 limit와 offset 구문을 사용한다.
이 방법은 초반부에서는 빠른 속도를 유지하면서 데이터를 조회할 수 있음. 하지만 뒤로 갈수록 느리게 조회된다.
윤님 블로그를 보면 5천만번 조회에서 대략 51초가 나옴. 대략 200만 데이터까지는 인덱스로 특정 범위의 행에 접근함. 그런데 그 이후로는 index를 타지 못하고 풀 스캔을 때려버림.

왜?
인덱스를 타는건 인덱스를 타지 않는 것보다 비용이 높음. 대략 100만건의 데이터가 있다면 50만 건을 읽어야 하는 쿼리가 있다고 하면 인덱스를 타서 50만건을 읽는게 효율적인지 인덱스를 타지 않고 전체 테이블을 스캔하고 50만건을 버리는게 효율적인지 옵티마이저가 정함.
일반적으로 DBMS의 옵티아미저에서 인덱스를 통해 레코드를 1건 읽는 것은 테이블에서 직접 레코드 1건을 읽는 것보다 4~5배 정도 비용이 발생한다고 예측합니다. 즉, 인덱스를 통해 읽어야 할 레코드의 건수(옵티마이저가 예측한)가 전체 테이블의 20~25%를 넘어서면 인덱스를 이용하지 않고 직접 테이블을 모두 읽어서 필요한 레코드만 필터링하는 방식이 효율적이라고 판단하게 됩니다.

따라서 데이터를 풀 스캔하고 디스크로부터 가져오기 떄문에 느릴 수 밖에 없음.

이를 해결하기 위해서는 카카오 정산팀에서는 ZeroOffsetPagingReader를 자체적으로 개발해서 사용하고 있음. 나는 그거 못함. 좀 더 공부해야함. 쿼리 DSL로 하는건데 왜냐하면 cursor 기반은 네이티브 쿼리로 짜야함. 네이티브로 짜면 실수할 여지가 굉장히 많기 때문에 쿼리 DSL + 코틀린으로 offset을 0으로 유지하면서 테이징하는 전략을 사용함. 이렇게 하면 항상 인덱스로 타고 가는 계획으로 동일해서 조회 시간이 균일함.


그런데 우리는 쿼리 DSL + 코틀린 + Exposed 사용이 안됨. 스택이 다름. 물론 학습하면 되지만 그럴 시간이 없다.

그래서 네이티브 쿼리를 사용한 JdbcCursorItemReader를 사용해야함.
커서를 사용해서 디비에 데이터를 조금씩 가져올 수 있음. JpaCursorItemReader도 있는데 얘는 데이터를 DB에서 모두 읽고 메모리에 올리기 때문에 OOM 유발함. 윤님 블로그가면 확인할 수 있는데 MYSQL 서버로부터 실행 결과를 모두 다운로드해 메모리에 올려버림. 사진 첨부

따라서 커서 기반은 jdbc꺼 써야함.
얘는 ResultSetStreaming 방식으로 데이터를 한건한건 들고옴. 사진 첨부
DB와 어플리케이션 사이에 커넥션을 물고 하나씩 데이터를 들고옴. 얘는 주의점이 네이티브 쿼리라 쿼리 작성하는데 주의해야 하고, 페이지네이션과 다르게 디비 커넥션을 계속 물고있음. 따라서 timeout이 날 수 있어서 기본적인 타임아웃 설정을 길게 잡아줘야 한다.











아이템 Reader는 Pagination 











## JpaPagingItemReader가 느린 이유




## 결론


## 참고자료

